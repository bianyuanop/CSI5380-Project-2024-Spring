{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import soundfile\n",
    "import json\n",
    "import io\n",
    "import requests\n",
    "\n",
    "host = \"http://localhost:4111\"\n",
    "text = \"I am voice number 22. I sound more stable than voice number 99\"\n",
    "sid = 22\n",
    "\n",
    "def tts(text: str):\n",
    "    resp = requests.post(host + '/tts', data={\n",
    "        \"text\": text,\n",
    "        \"sid\": sid\n",
    "    })\n",
    "\n",
    "    audiob64 = json.loads(resp.text)['audio']\n",
    "    audio_bytes = base64.b64decode(audiob64)\n",
    "    audio_file = io.BytesIO(audio_bytes)\n",
    "    audio_file.seek(0)\n",
    "    audio, sr = soundfile.read(audio_file)\n",
    "\n",
    "    return sr, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    tts,\n",
    "    gr.Text(),\n",
    "    \"audio\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api_key\"\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "USER: You are a helpful, medical specialist. Always answer as helpfully as possible.  If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. You always answer medical questions based on facts.\n",
    "ASSISTANT: Ok great ! I am a medical expert!\n",
    "USER: {question}\n",
    "ASSISTANT:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = OpenAI(openai_api_base=\"http://localhost:3000/v1\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What can I do about glenoid cavity injury ?\"\n",
    "\n",
    "result = llm_chain.run(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import intent\n",
    "\n",
    "# prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# llm = OpenAI(openai_api_base=\"https://api.openai.com/v1\")\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# question = \"What's the weather in Ottawa\"\n",
    "\n",
    "# result = llm_chain.run(question)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intent\n",
    "\n",
    "prompt = PromptTemplate(template=intent.intents['check-weather']['response-template'], input_variables=[\"location\", \"temperature\",])\n",
    "llm = OpenAI(openai_api_base=\"https://api.openai.com/v1\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "result = llm_chain.run(location='Ottawa', temperature='20C')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=intent.intents['open-app']['response-template'], input_variables=[\"app\",\"open_result\",])\n",
    "llm = OpenAI(openai_api_base=\"https://api.openai.com/v1\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "result = llm_chain.run(app=\"discord\", open_result=\"Opened\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intent import template\n",
    "\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(override=True)\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "p = re.compile('User Intent:.*')\n",
    "lp = re.compile('location:.*')\n",
    "s = '''User Intent:check-weather\n",
    "Slots:\n",
    "location:Ottawa'''\n",
    "\n",
    "matches = p.search(s)\n",
    "print(matches)\n",
    "matches = lp.search(s)\n",
    "print(matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
