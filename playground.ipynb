{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import soundfile\n",
    "import json\n",
    "import io\n",
    "import requests\n",
    "\n",
    "host = \"http://localhost:4111\"\n",
    "text = \"I am voice number 22. I sound more stable than voice number 99\"\n",
    "sid = 22\n",
    "\n",
    "def tts(text: str):\n",
    "    resp = requests.post(host + '/tts', data={\n",
    "        \"text\": text,\n",
    "        \"sid\": sid\n",
    "    })\n",
    "\n",
    "    audiob64 = json.loads(resp.text)['audio']\n",
    "    audio_bytes = base64.b64decode(audiob64)\n",
    "    audio_file = io.BytesIO(audio_bytes)\n",
    "    audio_file.seek(0)\n",
    "    audio, sr = soundfile.read(audio_file)\n",
    "\n",
    "    return sr, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    tts,\n",
    "    gr.Text(),\n",
    "    \"audio\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"api_key\"\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "USER: You are a helpful, medical specialist. Always answer as helpfully as possible.  If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. You always answer medical questions based on facts.\n",
    "ASSISTANT: Ok great ! I am a medical expert!\n",
    "USER: {question}\n",
    "ASSISTANT:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm = OpenAI(openai_api_base=\"http://localhost:3000/v1\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What can I do about glenoid cavity injury ?\"\n",
    "\n",
    "result = llm_chain.run(question)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import intent\n",
    "\n",
    "# prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# llm = OpenAI(openai_api_base=\"https://api.openai.com/v1\")\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# question = \"What's the weather in Ottawa\"\n",
    "\n",
    "# result = llm_chain.run(question)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intent\n",
    "\n",
    "prompt = PromptTemplate(template=intent.intents['check-weather']['response-template'], input_variables=[\"location\", \"temperature\",])\n",
    "llm = OpenAI(openai_api_base=\"https://api.openai.com/v1\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "result = llm_chain.run(location='Ottawa', temperature='20C')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chan/miniconda3/envs/csi5180/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/chan/miniconda3/envs/csi5180/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, I have successfully opened the Discord application for you. Is there anything else I can assist you with?\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=intent.intents['open-app']['response-template'], input_variables=[\"app\",\"open_result\",])\n",
    "llm = OpenAI(openai_api_base=\"https://api.openai.com/v1\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "result = llm_chain.run(app=\"discord\", open_result=\"Opened\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intent import template\n",
    "\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv(override=True)\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "p = re.compile('User Intent:.*')\n",
    "lp = re.compile('location:.*')\n",
    "s = '''User Intent:check-weather\n",
    "Slots:\n",
    "location:Ottawa'''\n",
    "\n",
    "matches = p.search(s)\n",
    "print(matches)\n",
    "matches = lp.search(s)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:19000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "host = os.environ['WHISPER_HOST']\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome.\n",
      "This is your text to voice generator speaking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "with open('./test.mp3', 'rb') as f:\n",
    "    files = {\n",
    "        'audio_file': f\n",
    "    }\n",
    "    resp = requests.post(os.path.join(host, 'asr'), headers={\n",
    "        'accept': 'application/json'\n",
    "    }, params={\n",
    "        'encode': True,\n",
    "        'task': 'transcribe',\n",
    "        'language': 'en',\n",
    "        'output': 'txt'\n",
    "    }, files=files)\n",
    "\n",
    "    print(resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome.\n",
      "This is your text to voice generator speaking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr: int = audio[0]\n",
    "    data: np.ndarray = audio[1]\n",
    "\n",
    "    bytes_wav = bytes()\n",
    "    f = io.BytesIO(bytes_wav)\n",
    "    write(f, sr, data)\n",
    "\n",
    "    files = {\n",
    "        'audio_file': f\n",
    "    }\n",
    "\n",
    "    resp = requests.post(os.path.join(host, 'asr'), headers={\n",
    "        'accept': 'application/json'\n",
    "    }, params={\n",
    "        'encode': True,\n",
    "        'task': 'transcribe',\n",
    "        'language': 'en',\n",
    "        'output': 'txt'\n",
    "    }, files=files)\n",
    "\n",
    "    print(resp.text)\n",
    "\n",
    "    return resp.text\n",
    "\n",
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\", \"upload\"]),\n",
    "    gr.Text() \n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csi5180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
